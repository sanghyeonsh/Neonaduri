
# 1일차
--- 
1. 하둡이란?
- 방대한 양의 데이터를 저장하고 구문 분석하는 모든 구성요소를 처리하기 위한 오픈 소스 프레임워크
- 적은 초기 비용으로 시작하여 여러 분석 기능을 사용할 수 있다.

2. 특징
- Hadoop Common : 대부분의 사용사례를 지원
- HDFS(Hadoop Distributed File System) : 하둡이 데이터를 저장하고, 맵리듀스를 통해 데이터를 처리
- MapReduce : 대규모 집합으로 매핑 후, 필터링해서 특정 결과 찾기
- Hadoop Yarn : 리소스 관리 및 일정 예약

3. 사용하는 이유
- 많은 데이터를 저장하면 로드를 처리하는 리소스와 하드웨어를 유지하는 데에 비용이 많이 든다
- hadoop은 접근성이 뛰어나고 유연한 방식으로 하드웨어를 사용할 수 있다. 
- 데이터 처리에 값비싼 하드웨어를 사용하는 대신에 여러 시스템에 처리 기능을 분산해서 사용
  => 자신에게 맞는 수량과 유형의 하드웨어를 사용하는 유연성 처리가능


# 2일차
---
: 행렬의 곱을 실행하는 것은 똑같지만, 데이터를 복사하는 방법에서의 차이가 있다.

  두가지의 형태를 모두 보도록 하자

## 1-phase matrix multiplication

- AxB를 진행할 때, key와 value를 각각 필요한 개수만큼 복사한다.
    
    (A는 axb, B는 bxc 행렬이라고 하자)
    
- key와 value 는 A와 B가 다르게 만들어진다
    - A : axb
        - A의 경우, 한개의 행 별로 B의 열과 만나서 값을 생성하게 된다.
        - 각 행의 개수는 B의 열의  값들과 만나게 될 것이고, 그 계산 결과 만들어지는 행렬에서는 한 행의 값들을 이루게 된다.
        - 그렇기 때문에 각 데이터는 **B의 열의 개수만큼 필요**하게 되고, 그 데이터는 해당 **열의 같은 순번의 값**과 곱해지게 된다!
        - key : (i,1),(i,2),(i,3) … (i,c)   [i는 A의 데이터의 행]
        - value : (j,v)   [j는 A데이터의 열 / v는 A데이터의 값]
    - B : bxc
        - B의 경우, 한 개의 열 단위로 A의 행과 부딪히게 된다.
        - 그렇기 때문에 데이터는 **A의 행의 개수**만큼 만들어지고, 이 때, 열 번호가 결과로 만들어진 **행렬의 열 번호**가 된다.
        - key : (1, j), (2,j), (3,j) … (a , j) [j는 B데이터의 열]
        - value : (i,v)   [i는 B데이터의 행 / v는 B데이터의 값]
        
- map에서 만든 (key, value)를 shuffle하게 되면, key값 별로 값들이 들어오게 된다. 이 때, key값은 결과로 나온 행렬의 행과 열을 의미하게 된다
- reducer에서는 앞에 같은 숫자별로 두개씩 들어오게 된다(A와 B에서 하나씩). 같은 숫자는 즉 곱해야하는 한 쌍이기 때문에 곱하게 되고, 그 결과 (총 b개)를 전부 더해주어서 해당 key값으로 내보내주면 된다!!

## 2-phase matrix Multiplication

- 메모리에 값을 많이 가지기 때문에, 이를 줄이는 방법으로 가보자

- 방법은 1-phase와 크게 다르지 않지만, key와 value를 담는 형태만 바뀌게 된다.
- A
    
    key : (i,1),(i, 2)…(i, c)   /    value : (j, v)
    
    ⇒key : (i,1,j),(i, 2, j)…(i, c, j)   /    value : (v)
    
- B
    
    key : (1, j), (2,j), (3,j) … (a , j)  /    value : (i,v)
    
    ⇒key : (1, j, i), (2,j, i), (3,j, i) … (a , j, i)  /    value : (v)
    
- 이렇게 하면, reducer에서 곱을 전부 더해야 결과 행렬의 데이터가 되는데, 이 경우 각 데이터별 곱들을 key와 value로 뽑아낼 수 있다.
- 즉, 곱들의 합을 1-phase에서는 reduce에서 전부처리했다면, 2-phase는 따로따로 해결해주는 형태로 보면 돤다!
- 그러면 왜 메모리가 사용되지 않을까?
    
    ⇒합을 하는 부분이 따로 빠져있기 때문에, 이 부분의 값들을 일회용으로 더하고 버려버릴 수 있기 때문이다





# 3일차
---
### 1. Theta Join Algorition

- 처음 들어보는 말이었지만, 결국은 **하나의 SQL문에 두 개의 테이블을 비교하는 방법**을 세타조인이라고 한다
- 그 때, Where 절을 **조인조건**(join-predicate)라고 한다
    - Equi-join : 조건절 중 =을 사용하는 조인

### 2. All Pair Partition Algorithm

- Theta join을 할 때, 비슷한 크기의 값들로 분산처리를 해서 계산을 할 수 있다.
    
    ⇒**모든 쌍 분할 알고리즘**
    
- 방법
    - 테이블 R과 S에 대해서, |R|*|S| 튜플 쌍을 다 고려함 (절댓값은 각 테이블의 데이터의 개수)
    - R과 S를 각각 u개 파티션과 v개 파티션으로 분할한다.
    - 이후, |R|*|S| 개의 튜플 쌍을 u*v개의 disjoint한 파티션으로 분할한다
    - 각각의 파티션을 한 개의 reduce 함수로 처리하게 된다!
- 장점
    - 어떤 조인조건이어도 처리 가능
    - 모든 reduce함수에 들어가는 입력 사이즈가 다 비슷
- 단점
    - 모든 튜플 쌍을 다 검사해야한다
    - 각각의 Reduce 함수의 출력 사이즈가 많이 다를 수 있다

### 2-1. All Partition Partition 이퀴조인 (Equi-join)

- 데이터들은 각 **파티션의 좌표**와 **파티션별로 들어가는 짝꿍의 개수**만큼의 데이터가 필요하게 된다
    - key : (Px,Py)   [Px : 파티션의 row  /   Py : 파티션의 column]
    - value : (matrix , index , value )  [matrix : 해당 행렬  /  index: matrix에서의 인덱스 / value: 값]





### 4일차
- All Pair Partition 알고리즘은 강력하지만, MxN 개의 쌍을 모두 확인해야 한다.
- 그 결과, 쌍이 이루어지지 않은 것들도 확인해봐야 하기 때문에 효율성이 떨어진다.
    
    ⇒ Inverted Index를 사용해서 값마다 계산해보자!
    

## 방법

---

1. Inverted Index table 만들기
    - 보통 id를 key로, values를 값들로 가지게 된다
    - 하지만 하나라도 값이 있는 것을 확인하기 위해서,  value별로 값으로 id를 가지도록 한다
        
        ⇒Inverted Index
        
2. Inverted Index table을 기준으로 Global Hash Table 만들기
    - 각 value별 id들을 전부 쌍으로 만들어준다.
        - Global Hash table에서 key는 id의 쌍, value는 그 쌍이 되는 값들의 개수이다
        - 그렇기 때문에, 하나씩 만들어서 table로 만들 때, global hash table에서 value들을 하나씩 올려주는 작업을 수행하게 된다
